{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969a51a2-004d-4f79-a8a6-c1cb6e5e5f09",
   "metadata": {},
   "source": [
    "## KNN ABLATION STUDY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aa837e-b1f6-48d7-876d-22d935e08e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL METRICS\n",
      "          Accuracy  Precision  Recall  F1 Score\n",
      "Baseline    0.9474     0.9302  0.9302    0.9302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(r\"C:\\Users\\rithy\\OneDrive\\Desktop\\python\\archive\\data.csv\") \n",
    "\n",
    "# 2. Drop the useless columns\n",
    "df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')\n",
    "\n",
    "# Clean strings and map diagnosis\n",
    "df['diagnosis'] = df['diagnosis'].astype(str).str.strip()\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Drop rows where diagnosis couldn't be mapped\n",
    "df = df.dropna(subset=['diagnosis'])\n",
    "\n",
    "# 3. Prepare X and y\n",
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "\n",
    "# 4. Scale features (Critical for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 5. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Initial KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 7. Record Original Metrics\n",
    "original_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'F1 Score': f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "print(\"ORIGINAL METRICS\")\n",
    "print(pd.DataFrame(original_metrics, index=['Baseline']).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157d0696-2381-43ac-a27f-212a653906ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Removed Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Acc Drop</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Removed Feature  Accuracy  Acc Drop  Precision    Recall  F1 Score\n",
       "0               radius_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "2            perimeter_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "3                 area_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "8             symmetry_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "7       concave points_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "6            concavity_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "10                radius_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "11               texture_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "13                  area_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "9    fractal_dimension_mean  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "17        concave points_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "16             concavity_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "15           compactness_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "14            smoothness_se  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "29  fractal_dimension_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "26          concavity_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "23               area_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "22          perimeter_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "21            texture_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "20             radius_worst  0.947368  0.000000   0.930233  0.930233  0.930233\n",
       "5          compactness_mean  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "1              texture_mean  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "27     concave points_worst  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "12             perimeter_se  0.956140 -0.008772   0.931818  0.953488  0.942529\n",
       "25        compactness_worst  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "19     fractal_dimension_se  0.956140 -0.008772   0.931818  0.953488  0.942529\n",
       "24         smoothness_worst  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "4           smoothness_mean  0.964912 -0.017544   0.953488  0.953488  0.953488\n",
       "18              symmetry_se  0.964912 -0.017544   0.953488  0.953488  0.953488\n",
       "28           symmetry_worst  0.964912 -0.017544   0.975610  0.930233  0.952381"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_results = []\n",
    "\n",
    "for feature in X.columns:\n",
    "    # 1. Drop feature and scale in one flow\n",
    "    X_temp = X.drop(columns=[feature])\n",
    "    X_temp_scaled = scaler.fit_transform(X_temp)\n",
    "    \n",
    "    # 2. Consistent Split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_temp_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 3. Fit & Predict\n",
    "    knn_temp = KNeighborsClassifier(n_neighbors=5).fit(X_tr, y_tr)\n",
    "    y_pr = knn_temp.predict(X_te)\n",
    "    \n",
    "    # 4. Store metrics\n",
    "    ablation_results.append({\n",
    "        'Removed Feature': feature,\n",
    "        'Accuracy': accuracy_score(y_te, y_pr),\n",
    "        'Precision': precision_score(y_te, y_pr),\n",
    "        'Recall': recall_score(y_te, y_pr),\n",
    "        'F1 Score': f1_score(y_te, y_pr)\n",
    "    })\n",
    "\n",
    "# Create DataFrame and calculate Drop\n",
    "ablation_df = pd.DataFrame(ablation_results)\n",
    "ablation_df['Acc Drop'] = original_metrics['Accuracy'] - ablation_df['Accuracy']\n",
    "\n",
    "# Reorder and Sort\n",
    "full_report = ablation_df[['Removed Feature', 'Accuracy', 'Acc Drop', 'Precision', 'Recall', 'F1 Score']]\n",
    "full_report = full_report.sort_values(by='Acc Drop', ascending=False)\n",
    "\n",
    "# Display as DataFrame\n",
    "full_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5339c-cc9e-4227-afc4-6518505855b7",
   "metadata": {},
   "source": [
    "### Observations :\n",
    "No single feature removal caused a performance drop, revealing that the dataset is highly **redundant** because geometric features like radius and area provide **overlapping information**. Also, several features acted as **noise**, meaning their removal actually sharpened the model's focus and **boosted accuracy**. \n",
    "This demonstrates that for **KNN**, a smaller, cleaner set of features is often more effective than a large, redundant one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1d672b-c891-4f8b-8c37-a8fdbbb85002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 NOISY FEATURES (REMOVAL IMPROVES METRICS)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Removed Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Acc Drop</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.942529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Removed Feature  Accuracy  Acc Drop  Precision    Recall  F1 Score\n",
       "4        smoothness_mean  0.964912 -0.017544   0.953488  0.953488  0.953488\n",
       "18           symmetry_se  0.964912 -0.017544   0.953488  0.953488  0.953488\n",
       "28        symmetry_worst  0.964912 -0.017544   0.975610  0.930233  0.952381\n",
       "1           texture_mean  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "19  fractal_dimension_se  0.956140 -0.008772   0.931818  0.953488  0.942529\n",
       "24      smoothness_worst  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "5       compactness_mean  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "12          perimeter_se  0.956140 -0.008772   0.931818  0.953488  0.942529\n",
       "27  concave points_worst  0.956140 -0.008772   0.952381  0.930233  0.941176\n",
       "25     compactness_worst  0.956140 -0.008772   0.952381  0.930233  0.941176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Sort by Acc Drop ascending (most negative = best improvement)\n",
    "top_10_noisy = ablation_df.sort_values(by='Acc Drop').head(10)\n",
    "\n",
    "# 2. Select and organize all metrics for the report\n",
    "noisy_report = top_10_noisy[[\n",
    "    'Removed Feature', \n",
    "    'Accuracy', \n",
    "    'Acc Drop', \n",
    "    'Precision', \n",
    "    'Recall', \n",
    "    'F1 Score'\n",
    "]]\n",
    "\n",
    "# 3. Extract the list of names for your final model training\n",
    "noisy_feature_list = top_10_noisy['Removed Feature'].tolist()\n",
    "\n",
    "# 4. Display as a DataFrame\n",
    "print(\"TOP 10 NOISY FEATURES (REMOVAL IMPROVES METRICS)\")\n",
    "noisy_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1794724c-dfab-43f4-bad1-b2d7ce6637d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS WITHOUT NOISY FEATURES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.973684\n",
       "1  Precision  0.976190\n",
       "2     Recall  0.953488\n",
       "3   F1 Score  0.964706"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Drop the 10 noisy features\n",
    "X_optimized = X.drop(columns=noisy_feature_list)\n",
    "\n",
    "# 2. Re-scale the reduced feature set\n",
    "X_opt_scaled = scaler.fit_transform(X_optimized)\n",
    "\n",
    "# 3. Split the data\n",
    "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(\n",
    "    X_opt_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Train and Evaluate\n",
    "knn_final = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_final.fit(X_train_o, y_train_o)\n",
    "y_pred_o = knn_final.predict(X_test_o)\n",
    "\n",
    "# 5. Final results in a DataFrame\n",
    "print(\"METRICS WITHOUT NOISY FEATURES\")\n",
    "final_results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [\n",
    "        accuracy_score(y_test_o, y_pred_o),\n",
    "        precision_score(y_test_o, y_pred_o),\n",
    "        recall_score(y_test_o, y_pred_o),\n",
    "        f1_score(y_test_o, y_pred_o)\n",
    "    ]\n",
    "})\n",
    "\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf492f-b277-4134-ad35-c2f679bcd7fd",
   "metadata": {},
   "source": [
    "### KNN FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae40db2a-83f6-4b89-b988-6b9835ac8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    distance = np.sqrt(np.sum((x1-x2)**2))\n",
    "    return distance\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # 1. Compute distances between x and all examples in the training set\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "    \n",
    "        # 2. Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # 3. Extract the labels of the k nearest neighbor training samples\n",
    "        # Using iloc or just simple indexing if it's a numpy array\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # 4. Majority vote, most common class label\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01912ca6-048c-44c7-812d-263dd2f12dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRATCH KNN MODEL PERFORMANCE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.929825\n",
       "1  Precision  0.911111\n",
       "2     Recall  0.911111\n",
       "3   F1 Score  0.911111"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df.drop(columns=['diagnosis']).values \n",
    "y = df['diagnosis'].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = KNN(k=5)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Convert your scratch predictions to a standard NumPy array\n",
    "y_pred_scratch = np.array(predictions)\n",
    "\n",
    "# Calculate the four metrics\n",
    "metrics_scratch = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [\n",
    "        accuracy_score(y_test, y_pred_scratch),\n",
    "        precision_score(y_test, y_pred_scratch),\n",
    "        recall_score(y_test, y_pred_scratch),\n",
    "        f1_score(y_test, y_pred_scratch)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display in a clean DataFrame\n",
    "scratch_results_df = pd.DataFrame(metrics_scratch)\n",
    "\n",
    "print(\"SCRATCH KNN MODEL PERFORMANCE\")\n",
    "scratch_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a8e95-2311-4278-99a3-159fd715cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "379acac5-8de8-4f66-b99d-7d0e6a33b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in c:\\users\\rithy\\appdata\\roaming\\python\\python313\\site-packages (1.5.2)\n",
      "Model_1_Decision_tree Performance\n",
      "Accuracy : 0.9533333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.98      0.88      0.93        50\n",
      "   virginica       0.89      0.98      0.93        50\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.96      0.95      0.95       150\n",
      "weighted avg       0.96      0.95      0.95       150\n",
      "\n",
      "Model_2_Logistic_Regression Performance\n",
      "Accuracy : 0.9733333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.98      0.94      0.96        50\n",
      "   virginica       0.94      0.98      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Model_3_KNN Performance\n",
      "Accuracy : 0.9666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.98      0.92      0.95        50\n",
      "   virginica       0.92      0.98      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Model_4_SVM Performance\n",
      "Accuracy : 0.9733333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.98      0.94      0.96        50\n",
      "   virginica       0.94      0.98      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Model_5_Random_Forest Performance\n",
      "Accuracy : 0.9666666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.94      0.96      0.95        50\n",
      "   virginica       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#joblib for loading pickle files\n",
    "!pip install joblib\n",
    "#Essential libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris=load_iris()\n",
    "X =iris.data   # features\n",
    "y=iris.target  # target variable \n",
    "df=pd.DataFrame(X,columns=iris.feature_names)  #converting to dataframe\n",
    "df['species']=iris.target\n",
    "\n",
    "X.shape  # To verify correct input dimensions\n",
    "\n",
    "# Model 1\n",
    "model1_DT = joblib.load(open(r\"C:\\Users\\rithy\\Downloads\\model1_decision_tree (1).pkl\", 'rb')) #load pickle file containing pretrained model\n",
    "model1_DT.classes_  # To confirm label compatibility\n",
    "y_pred_DT = model_DT.predict(X) # Predictions made for all features without splitting\n",
    "class_report = classification_report(y, y_pred_DT, target_names=iris.target_names) # classification report\n",
    "print(\"Model_1_Decision_tree Performance\")\n",
    "print(\"Accuracy :\",accuracy_score(y,y_pred_DT)) # Accuracy\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Same process for all other models\n",
    "\n",
    "# Model 2\n",
    "model2_logreg = joblib.load(open(r\"C:\\Users\\rithy\\Downloads\\model2_logistic_regression.pkl\", 'rb'))\n",
    "model2_logreg.classes_\n",
    "y_pred_logreg = model_logreg.predict(X)\n",
    "class_report = classification_report(y, y_pred_logreg, target_names=iris.target_names)\n",
    "print(\"Model_2_Logistic_Regression Performance\")\n",
    "print(\"Accuracy :\",accuracy_score(y,y_pred_logreg))\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Model 3\n",
    "model3_knn = joblib.load(open(r\"C:\\Users\\rithy\\Downloads\\model3_knn.pkl\", 'rb'))\n",
    "model3_knn.classes_\n",
    "y_pred_knn = model_knn.predict(X)\n",
    "class_report = classification_report(y, y_pred_knn, target_names=iris.target_names)\n",
    "print(\"Model_3_KNN Performance\")\n",
    "print(\"Accuracy :\",accuracy_score(y,y_pred_knn))\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Model 4\n",
    "model4_svm = joblib.load(open(r\"C:\\Users\\rithy\\Downloads\\model4_svm.pkl\", 'rb'))\n",
    "model4_svm.classes_\n",
    "y_pred_svm = model_svm.predict(X)\n",
    "class_report = classification_report(y, y_pred_svm, target_names=iris.target_names)\n",
    "print(\"Model_4_SVM Performance\")\n",
    "print(\"Accuracy :\",accuracy_score(y,y_pred_svm))\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Model 5\n",
    "model5_RF = joblib.load(open(r\"C:\\Users\\rithy\\Downloads\\model5_random_forest.pkl\", 'rb'))\n",
    "model5_RF.classes_\n",
    "y_pred_RF = model_RF.predict(X)\n",
    "class_report = classification_report(y, y_pred_RF, target_names=iris.target_names)\n",
    "print(\"Model_5_Random_Forest Performance\")\n",
    "print(\"Accuracy :\",accuracy_score(y,y_pred_RF))\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478efcc-c609-45d5-b79e-c713408652fe",
   "metadata": {},
   "source": [
    "**Macro avg** was used instead of weighted avg because the Iris dataset is balanced, ensuring equal importance is given to all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "647eef9f-277b-4ebc-b264-cbb03551ed81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.956229</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.967751</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.973323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966787</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Macro Precision  Macro Recall  \\\n",
       "0        Decision Tree  0.953333         0.956229      0.953333   \n",
       "1  Logistic Regression  0.973333         0.973825      0.973333   \n",
       "2                  KNN  0.966667         0.967751      0.966667   \n",
       "3                  SVM  0.973333         0.973825      0.973333   \n",
       "4        Random Forest  0.966667         0.966787      0.966667   \n",
       "\n",
       "   Macro F1-score  \n",
       "0        0.953216  \n",
       "1        0.973323  \n",
       "2        0.966637  \n",
       "3        0.973323  \n",
       "4        0.966663  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a comparison table for all models\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"Model\": [\"Decision Tree\",\"Logistic Regression\",\"KNN\",\"SVM\",\"Random Forest\" ],\n",
    "    \"Accuracy\": [accuracy_score(y, y_pred_DT),accuracy_score(y, y_pred_logreg),accuracy_score(y, y_pred_knn),accuracy_score(y, y_pred_svm),accuracy_score(y, y_pred_RF) ],\n",
    "    \"Macro Precision\": [classification_report(y, y_pred_DT, output_dict=True)[\"macro avg\"][\"precision\"],classification_report(y, y_pred_logreg, output_dict=True)[\"macro avg\"][\"precision\"],classification_report(y, y_pred_knn, output_dict=True)[\"macro avg\"][\"precision\"], classification_report(y, y_pred_svm, output_dict=True)[\"macro avg\"][\"precision\"],classification_report(y, y_pred_RF, output_dict=True)[\"macro avg\"][\"precision\"]],\n",
    "    \"Macro Recall\": [classification_report(y, y_pred_DT, output_dict=True)[\"macro avg\"][\"recall\"],classification_report(y, y_pred_logreg, output_dict=True)[\"macro avg\"][\"recall\"],classification_report(y, y_pred_knn, output_dict=True)[\"macro avg\"][\"recall\"],classification_report(y, y_pred_svm, output_dict=True)[\"macro avg\"][\"recall\"],classification_report(y, y_pred_RF, output_dict=True)[\"macro avg\"][\"recall\"]],\n",
    "    \"Macro F1-score\": [classification_report(y, y_pred_DT, output_dict=True)[\"macro avg\"][\"f1-score\"],classification_report(y, y_pred_logreg, output_dict=True)[\"macro avg\"][\"f1-score\"],classification_report(y, y_pred_knn, output_dict=True)[\"macro avg\"][\"f1-score\"],classification_report(y, y_pred_svm, output_dict=True)[\"macro avg\"][\"f1-score\"],classification_report(y, y_pred_RF, output_dict=True)[\"macro avg\"][\"f1-score\"]]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef6a93-fe92-4b78-bdc1-4002929f55e2",
   "metadata": {},
   "source": [
    "**Decision Tree** achieved slightly lower accuracy due to its tendency to overfit and make rigid splits, leading to minor misclassification between Versicolor and Virginica.\n",
    "**KNN** performed well by leveraging local neighborhood information but showed marginal sensitivity to overlapping classes.\n",
    "**Random Forest** improved robustness over a single decision tree through ensemble learning, resulting in stable performance but without outperforming the best linear models on this simple dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc136afa-d5f2-461c-8bc6-5ba1ad44f68b",
   "metadata": {},
   "source": [
    "Although **Logistic Regression** and **SVM** achieved identical performance metrics, SVM was preferred due to its margin maximization principle, which constructs a more robust decision boundary between overlapping classes.\n",
    "This property allows **SVM** to generalize better and be less sensitive to outliers compared to Logistic Regression, making it a safer choice when class boundaries are not perfectly separable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29a7d024-a305-4a27-9b72-7222922b554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=InconsistentVersionWarning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
